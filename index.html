<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Geometry-Guided Self-Supervised Learning for Category-Level Object Pose Estimation in Robotic Grasping.">
  <meta name="keywords" content="Pose estimation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Geometry-Guided Self-Supervised Learning for Category-Level Object Pose Estimation in Robotic Grasping</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Test-time Model Adaptation for Robotic Grasping with Weakly Supervised Affordance Grounding</h1>
          <div class="is-size-5 publication-authors">
            <!-- <span class="author-block">
              <a href="">author 1</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">author 2</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">author 3</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://zychaoqun.wixsite.com/chaoqun">Chaoqun Wang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://irmv.sjtu.edu.cn/">Hesheng Wang</a><sup>3</sup>,
            </span> -->
          </div>

          <div class="is-size-5 publication-authors">
            <!-- <span class="author-block"><sup>1</sup>China University of Mining and Technology,</span>
            <span class="author-block"><sup>2</sup>Shandong University,</span>
            <span class="author-block"><sup>3</sup>Shanghai Jiao Tong University</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://youtu.be/A6L95qo07fc?si=V3vvSy4ybnM9tupV"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="video-handsan" autoplay muted loop height="100%">
            <source src="media/intro/1_holdKnife.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="video-food-bin" autoplay muted loop height="100%">
            <source src="media/intro/2_typeonboard.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="video-drawer" autoplay muted loop height="100%">
            <source src="media/intro/3_pickupapple.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="video-marker" autoplay muted loop height="100%">
            <source src="media/intro/4_liftthebottle.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="video-stick" autoplay muted loop height="100%">
            <source src="media/intro/5_pickupthebox.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="video-sweeping" autoplay muted loop height="100%">
            <source src="media/intro/6_swingtheracket.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Affordance grounding facilitates the identification of suitable manipulation regions on target objects for intended actions, playing a pivotal role in the robotic manipulation of unknown objects within dynamic scenarios. Current methods mainly focus on weakly supervised strategies to address the challenge of extensive data annotation requirements. Nevertheless, they fail to account for the inherent scarcity and dynamic distribution characteristics of acquired data in real-world applications, which inevitably leads to performance degradation. Consequently, in this paper, we propose to incorporate the test-time adaptation technique with knowledge transferring structure to empower robots the ability to cope with dynamically changing environments. Specifically, to transfer the learned knowledge of affordance grounding for the subsequent model optimization process using the online perceived data, we propose to integrate the teacher-student architecture with existing models to facilitate knowledge sharing. Additionally, we design a salient knowledge transferring module to selectively preserve the high-quality grounding knowledge from teacher model. Furthermore, to enhance the prediction accuracy of the student model, we introduce an entropy-augmented affordance grounding module to restrict the prediction space of the model. Finally, conditioned on predicted affordance map,we employ typical 2D grasping methods using a parallel - plate gripper to perform the manipulation task. Extensive quantitative and qualitative experiments on datasets and real-world robotic grasping tasks demonstration the effectiveness and superiority of our proposed methods.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Video</h2>
    <div class="publication-video">
      <video width="1080" height="720" controls muted playsinline preload="auto" style="max-width: 100%; border: none;">
        <!-- 替换 src 为你的本地视频路径（相对路径或绝对路径均可） -->
        <source src="./static/videos/my.mp4" type="video/mp4">
      </video>
    </div>
  </div>
</div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
  <h2 class="title is-3">Main Architecture</h2>
        <!-- 移除面板的背景和边框 -->
        <div class="columns is-vcentered interpolation-panel" style="background: none; border: none;">
          <div class="column is-full has-text-centered">
            <!-- 移除图片的边框和背景 -->
            <img src="./static/images/mainarch.png" 
                class="interpolation-image" 
                alt="Main archimage" 
                style="border: none; background: none;"/>
          </div>
        </div>
        <p> The framework of Aff-Grasp. It first employs an open-vocabulary detector to locate all objects within the scene, which are then sent to GAT to determine if they possess the corresponding affordance required for the task. Afterwards, a 6 DoF grasp generation model, Contact-GraspNet, leverages the object's graspable affordance and the depth map to generate dense grasp proposals. Finally, the robot executes affordance-specific sequential motion primitives to apply the functional part to the target.
        </p>
        
        <h2 class="title is-3">Qualitative Results</h2>

        <!-- Results on AGD20K-Seen -->
        <h3 class="title is-4">Results on AGD20K-Seen</h3>
        <div class="content has-text-justified">
          <p>
            We present some additional prediction results of our method on AGD20K-Seen dataset.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-full has-text-centered"> <!-- 使用is-full让图片占满一行 -->
              <img src="./static/images/agd20k_seen.png" class="interpolation-image" alt="AGD20K-Seen example image"/>
          </div>
        </div>

        <!-- Results on AGD20K-Unseen -->
        <h3 class="title is-4">Results on AGD20K-Unseen</h3>
        <div class="content has-text-justified">
          <p>
            We present some additional prediction results of our method on AGD20K-Unseen dataset.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-full has-text-centered">
              <img src="./static/images/agd20k_unseen.png" class="interpolation-image" alt="AGD20K-Unseen example image"/>
          </div>
        </div>

        <!-- Results on HICO -->
        <h3 class="title is-4">Results on HICO</h3>
        <div class="content has-text-justified">
          <p>
            We present some additional prediction results of our method on HICO dataset.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-full has-text-centered">
              <img src="./static/images/hico.png" class="interpolation-image" alt="HICO example image"/>
          </div>
        </div>
        <!-- Results on HICO -->
        <h3 class="title is-4">Results on Real-world</h3>
        <div class="content has-text-justified">
          <p>
            We present some additional prediction results of our method on real-world dataset.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-full has-text-centered">
              <img src="./static/images/realworld.png" class="interpolation-image" alt="HICO example image"/>
          </div>
        </div>

      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{mypaper,
  author    = {},
  title     = {},
  year      = {},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            Website template borrowed from <a rel="license" href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> and <a rel="license" href="https://peract.github.io/">PerAct</a> .
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
